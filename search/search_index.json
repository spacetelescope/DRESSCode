{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DRESSCode: Swift data reduction","text":"<p> DRESSCode logo designed by J. De Wree </p> <p>DRESSCode, short for Data Reduction of Extended Swift Sources Code, is a fully automated pipeline to reduce Swift UVOT images of extended sources. It consists of a series of python scripts that perform the different steps of the data reduction pipeline to all images. The different steps include preparation, creation of sky images, aspect correction, creation of auxiliary maps, combination of separate frames, several corrections to the flux, combination of different observing periods, calibration, and aperture correction. DRESSCode is a two-phase pipeline, which means that some steps are repeated a second time, in order to improve the accuracy of the astrometry of the images.</p> <p>For the original version of this software, see mdecleir/DRESSCode.</p> <p>Documentation: https://spacetelescope.github.io/DRESSCode/</p> <p>Source Code: https://github.com/spacetelescope/DRESSCode/</p>"},{"location":"#requirements","title":"Requirements","text":"<p>DRESSCode has been written and tested on Linux and Mac, and relies on several tasks from the specialized HEASoft software, provided by NASA.</p> <p>See the documentation for specific installation instructions.</p> <p>The minimum requirements are:</p> <ul> <li>Python 3.7 or later</li> <li>Current version of HEASoft (tested with 6.28)</li> <li>caldb: calibration tree</li> <li>wcstools: World Coordinate System utilities</li> </ul>"},{"location":"#docker","title":"Docker","text":"<p>Docker can be used to run the software without having to complete the HEASoft/caldb/wcstools installation procedure yourself (or to run on windows). The image can be found on docker hub.</p> <p>To download and open an interactive shell:</p> <pre><code>docker pull dresscodeswift/dresscode\ndocker run --rm -it dresscodeswift/dresscode /bin/bash\n</code></pre> <p>From there run the pipeline, which is located in <code>/opt/dresscode</code></p> <p>For more, see our docker instructions.</p>"},{"location":"#help","title":"Help","text":"<p>Please see the documentation. If you encounter a bug or have questions, please report through GitHub issues.</p>"},{"location":"#license","title":"License","text":"<p>This project is Copyright Association of Universities for Research in Astronomy and licensed under the terms of the BSD 3-Clause \u201cNew\u201d or \u201cRevised\u201d License (see the LICENSE file for more information).</p>"},{"location":"#use-cases-and-publications","title":"Use cases and publications","text":"<ul> <li>Decleir et al. (2019) used a slightly older version of the DRESSCode (with only one phase) to reduce the Swift UVOT images of NGC628. These images were used to measure dust attenuation curves on resolved scales in NGC628. The paper also describes the details of the older version of the pipeline.</li> <li>The current version of the DRESSCode was used in the DustKING project, to reduce the Swift UVOT images of all KINGFISH galaxies. The goal of this project is to measure the global dust attenuation curves of all KINGFISH galaxies. This work will be published soon (Decleir et al., in prep.). The preliminary results of this work can be found in Chapter 4 of Marjorie Decleir's PhD thesis.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We encourage contributions. If you have ideas for the project or have found a bug, please submit an issue.</p> <p>For more information on contributing, see developer notes.</p>"},{"location":"LICENSE/","title":"LICENSE","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2021, Association of Universities for Research in Astronomy. All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"developer_notes/","title":"Developer's notes","text":"<p>We use <code>black</code> and <code>isort</code> for autoformatting and <code>flake8</code> for linting.</p> <p>You are encouraged to add editor support (enable autoformat on save w/ black) and show linting errors with flake8. See the documentation for your editor to set up.</p> <p>To manually run each of the tools:</p> <p>black:</p> <pre><code>black . --check --diff\n</code></pre> <p>isort:</p> <pre><code>isort . --check --diff\n</code></pre> <p>flake8:</p> <pre><code>flake8 .\n</code></pre> <p>We also have pre-commit hooks. You can install them with <code>pre-commit install</code></p>"},{"location":"developer_notes/#requirements-file","title":"Requirements file","text":"<p>We use pip-tools to manage requirements.</p> <p>Install pip-tools:</p> <p><code>python -m pip install pip-tools</code></p> <p>Compile requirements:</p> <p><code>pip-compile --quiet</code></p>"},{"location":"download_data/","title":"Download and prepare the SWIFT data","text":""},{"location":"download_data/#download-the-data","title":"Download the data","text":"<ul> <li>Go to NASA\u2019s HEASARC Archive: https://heasarc.gsfc.nasa.gov/cgi-bin/W3Browse/swift.pl</li> <li>Next to \u201cUVOT Log\u201d, click on \u201cparameter search form\u201d to open the SWIFT UVOT Data Query form.</li> <li> <p>Use the following parameters (and leave the other parameters to the default values):</p> filter <code>UVW2</code> OR <code>UVM2</code> OR <code>UVW1</code> pointing_mode POINTING Object Name Name of the galaxy, e.g. NGC0628 </li> <li> <p>Click on the \u201cStart Search\u201d button and wait for the query results to load.</p> </li> <li>Check the box \u201cSelect All\u201d to select all data.</li> <li>At the bottom: Select \u201cSwift Auxiliary Data (aux)\u201d and \u201cSwift UVOT Data (uvot data)\u201d.</li> <li>Click on the \u201cCreate Download Script\u201d button and wait for the new tab to load.</li> <li>Click on the \u201cDownload Commands To File\u201d button and wait until the script is downloaded.</li> <li>Create a new directory somewhere on your computer with the name of the galaxy, e.g. \u201cNGC0628\u201d, and create a new directory within that directory with the name \u201cRaw_data\u201d.</li> <li> <p>Move the download script to the \u201cRaw_data\u201d directory and run it:</p> <pre><code>bash browse_download_script.txt\n</code></pre> </li> </ul> <p>Downloading the data can take a while!</p>"},{"location":"download_data/#sort-and-select-the-required-data","title":"Sort and select the required data","text":"<p>In order to execute the full pipeline, it is recommended to keep the same directory structure as explained here and in data download. The user then only needs to change the galaxy name and the path of the main directory in the configuration file <code>config.txt</code> before running the scripts (see config.txt.example).</p> <ul> <li>The download script will automatically sort the data into different directories according to the observing ID of the exposure. The directory structure is somewhat complex, but you should not worry about that. If you used the same directory structure as described above, the only thing you need to do to make all scripts work, is to change the name of the galaxy and the path of the main directory (in which the different galaxy directories are located) in the <code>config.txt</code> file.</li> <li>Run the script <code>dc-collect_images</code> to collect all the UV raw image (<code>*_rw.img.gz</code>) files from the uvot/image/ folders, the UV event files (<code>*w1po_uf.evt.gz</code>) from the uvot/event/ folders, the attitude (<code>*pat.fits.gz</code>) files from the auxil/ folders and the aspect following (<code>*uaf.hk.gz</code>) files from the uvot/hk/ folders. This will create the directory \u201cRaw_images\u201d in the current directory (e.g. \u201cNGC0628\u201d).</li> <li>To save space on your computer, you can now delete the \u201cRaw_data\u201d directory, if you want.</li> <li>Extract (decompress) all files in the \u201cRaw_images\u201d directory. To save space on your computer, you can now delete the compressed (<code>*.gz</code>) files, if you want.</li> <li>Copy the entire \u201cRaw_images\u201d directory to a new working directory with the name \u201cworking_dir\u201d, in which all the temporary files will be stored during the reduction process. Make sure you always keep the raw files in the \u201cRaw_images\u201d directory in case you want to restart.</li> </ul>"},{"location":"install/","title":"Installation Instructions","text":""},{"location":"install/#docker-installation","title":"Docker Installation","text":"<p>Docker can be used to run the software without having to complete the HEASoft/caldb/wcstools installation procedure yourself (or to run on windows). The image can be found on docker hub. It also includes the latest version of the DRESSCode pipeline, along with any other python dependencies.</p> <p>To download and open an interactive shell with the prerequisites already installed:</p> <pre><code>docker pull dresscodeswift/dresscode\ndocker run --rm -it dresscodeswift/dresscode /bin/bash\n</code></pre> <p>From there run the pipeline, which is located in <code>/opt/dresscode</code></p> <p>You will probably want to download the data onto a persistent volume and mount it in your docker image as you run the pipeline. For this, see docker's storage volume documentation.</p>"},{"location":"install/#local-installation","title":"Local Installation","text":"<p>The following steps will install Heasoft, caldb, and wcstools on your machine</p>"},{"location":"install/#download-heasoft-software","title":"Download Heasoft software","text":"<ul> <li>Go to https://heasarc.gsfc.nasa.gov/docs/software/lheasoft/download.html</li> <li>STEP 1<ul> <li>Select the type of software: Choose \"SOURCE CODE DISTRIBUTION\"</li> <li>Choose your platform, e.g. \"PC - Ubuntu Linux 20.04\"</li> </ul> </li> <li>STEP 2<ul> <li>Download the desired packages: Select the \"Swift\" mission (all FTOOLS and XANADU will automatically be selected)</li> </ul> </li> <li>Submit and wait</li> <li>Untar the file</li> </ul>"},{"location":"install/#installbuild-heasoft-software","title":"Install/Build Heasoft software","text":"<ul> <li>STEP 3 - Install the software: Follow the installation guide for your platform, e.g. \"PC Linux - Ubuntu (or other Debian-based Linux)\".</li> </ul> <p>All subsequent steps are for Ubuntu platforms:</p> <ul> <li>Install the prerequisite packages listed here: https://heasarc.gsfc.nasa.gov/lheasoft/ubuntu.html</li> <li>Build the software following the instructions in the installation guide (https://heasarc.gsfc.nasa.gov/lheasoft/ubuntu.html)</li> <li> <p>Add the following lines to your <code>.bashrc</code> (or equivalent):</p> <pre><code>export HEADAS=~/heasoft-6.28/x86_64-pc-linux-gnu-libc2.23\n. $HEADAS/headas-init.sh\n</code></pre> </li> </ul>"},{"location":"install/#install-the-calibration-tree","title":"Install the calibration tree","text":"<ol> <li>Create a new folder \u201ccaldb\u201d in the heasoft-6.28 folder</li> <li>Follow the instructions on: https://heasarc.gsfc.nasa.gov/docs/heasarc/caldb/install.html (Sections 2 and 3)</li> </ol>"},{"location":"install/#install-wcstools","title":"Install wcstools","text":"<ol> <li>Download the current version (3.9.7) from http://tdc-www.harvard.edu/software/wcstools/wcstools-3.9.7.tar.gz</li> <li>Put the tarfile in your home folder and untar</li> <li> <p>Install the tools:</p> <pre><code>cd wcstools-3.9.7\nmake all\n</code></pre> </li> <li> <p>Add the following line to your <code>.bashrc</code> (or equivalent):</p> <pre><code>export PATH=~/wcstools-3.9.7/bin:$PATH\n</code></pre> </li> </ol> <p>More info can be found on the wcstools website.</p>"},{"location":"install/#install-dresscode","title":"Install DRESSCode","text":"<p>Requires Python &gt;= 3.7. Make sure you have a working python environment (it is probably best to create a new environment to work with DRESSCode). Then install from source:</p> <pre><code>python -m pip install git+https://github.com/spacetelescope/DRESSCode\n</code></pre> <p>Alternatively, clone the repo to a directory &amp; install from there:</p> <ol> <li><code>git clone git@github.com:spacetelescope/DRESSCode.git</code></li> <li><code>cd DRESSCode</code></li> <li>Create a virtual environment: <code>python3 -m venv venv</code></li> <li><code>python -m pip install .</code> or for an editable install <code>python -m pip install -e .</code></li> </ol> <p>To install extra dev dependencies: <code>python -m pip install -e \".[dev]\"</code></p>"},{"location":"notes/","title":"General notes to the user","text":"<ul> <li>Make sure the HEASoft and WCSTools are correctly installed and initialized (see install guide). Without these tools, you won\u2019t be able to run the pipeline.</li> <li>Make sure you are using Python 3.7 or later, and that all required modules are installed properly. The script will emit an error message if a module or package is missing.</li> <li>Check the output after each step.</li> <li>Questions/problems can be reported through GitHub issues.</li> </ul>"},{"location":"usage/","title":"Using DRESSCode","text":"<p>Note: The details of the different steps in the pipeline are explained in Chapter 2 of Marjorie Decleir's PhD thesis.</p> <p>Before running these steps, make sure you have installed the software and downloaded and prepared the data.</p>"},{"location":"usage/#run-the-entire-pipeline","title":"Run the entire pipeline","text":"<p>To run the entire pipeline, you can run this script: <code>pipeline.bash</code>. To run the pipeline step-by-step, see instructions below.</p>"},{"location":"usage/#step-by-step","title":"Step by step","text":""},{"location":"usage/#sky-images-part-1","title":"Sky images part 1","text":"<p>Run the script <code>dc-uvotimage</code> to create sky images from the raw images and event files. When your data contains event files, you will get the following warning:</p> <p><code>uvotimage: skipping event based image HDU w1386106344E in file sw00032766001uw1_rw.img</code></p> <p>This means that the code is skipping the event based frames in the raw images to prevent using the event data twice. This is perfectly normal, and you can thus ignore this warning.</p>"},{"location":"usage/#aspect-correction-part-1","title":"Aspect correction part 1","text":"<ul> <li> <p>Run the script <code>dc-uvotskycorr</code> to calculate an aspect correction for the sky images. If no aspect correction could be found, the following warning will appear:</p> <p><code>!! No aspect correction found for frame sw00450884000_evt_uw2_sk.img[1]!!</code></p> <p>To solve this, you can try to increase the number of reference stars used by the task. In the script you will find: <code>n.reference=200 n.observation=40</code>. <code>n.reference</code> is the maximum number of reference stars that will be used from the catalog. <code>n.observation</code> is the maximum number of observed stars in the image that will be used to match with the catalog. Increasing one (or both) of these values can help to find an aspect correction. Of course, this will also increase the running time. Too high values can cause the process to crash, for example when your computer is short of memory. Frames for which no aspect correction was found, will not be taken into account in the summed image (see Summing images per observing period).</p> </li> <li> <p>Run the script <code>dc-uvotattcorr</code> to adjust the attitude files with the calculated aspect corrections.</p> </li> </ul>"},{"location":"usage/#sky-images-part-2","title":"Sky images part 2","text":"<p>Run the script <code>dc-uvotimage2</code> to create new sky images from the raw images, using the updated attitude files.</p>"},{"location":"usage/#auxiliary-files-part-1","title":"Auxiliary files part 1","text":"<ul> <li>Run the script <code>dc-uvotbadpix</code> to create quality maps for all sky images.</li> <li>Run the script <code>dc-uvotexpmap</code> to create exposure maps for all sky images, to flag the sss patches in the quality maps, and to create mask maps based on the quality maps.</li> </ul> <p>Small scale sensitivity (sss) patches are detector regions with a lower throughput, probably caused by dust on the photocathode. There is no way to correct for the count loss in the affected pixels. Therefore, the only solution is to mask these regions in the images. The script <code>dc-uvotexpmap</code> will flag these pixels in the quality maps. At this stage, only raw image files of 1024x1024 or 2048x2048 pixels can be used. Some galaxies have images with a different dimension. For these images, an sss mask cannot be created, because it is a priori not known which part of the detector was exposed. These images should thus not be used in the pipeline. When the script encounters an image with a different dimension, the following warning will appear:</p> <p><code>Quality map quality_sw00032081026_uat_img_uw1_badpix.img[1] does not have the correct dimensions, and cannot be combined with an sss mask.</code></p> <p>Make sure to delete these images before continuing!</p>"},{"location":"usage/#aspect-correction-part-2","title":"Aspect correction part 2","text":"<p>Run the script <code>dc-uvotskycorr2</code> to calculate an aspect correction and apply it to the sky images, the exposure maps and the mask files, using the updated attitude files.</p>"},{"location":"usage/#auxiliary-files-part-2","title":"Auxiliary files part 2","text":"<p>Run the script <code>dc-uvotskylss</code> to create large scale sensitivity (lss) maps for all sky images.</p>"},{"location":"usage/#flux-corrections","title":"Flux corrections","text":"<p>Run the script <code>dc-corrections</code> to correct the normalized images for coincidence loss, large scale sensitivity variations, and loss of detector sensitivity (i.e. zero point correction).</p>"},{"location":"usage/#summing-images","title":"Summing images","text":"<ul> <li>Run the script <code>dc-uvotimsum</code> to sum all frames per type and per filter and to normalize the total sky images. Image frames for which no aspect correction was found, will automatically be excluded from the sum.</li> </ul>"},{"location":"usage/#calibration-and-aperture-correction","title":"Calibration and aperture correction","text":"<p>Use the script <code>dc-calibration</code> to convert the units of the final images from counts/s to Jy and to perform an \u201cinverse\u201d aperture correction.</p>"}]}